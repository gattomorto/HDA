Modify your train_model function:
Replace the manual training loop with model.fit() to leverage built-in TensorBoard integration.
Alternatively, keep your loop but add manual profiling

https://www.tensorflow.org/guide/data_performance

Data preprocessing: you may increase num_parallel_calls in Dataset map() or preprocess the data OFFLINE.

Reading data from files in advance: you may tune parameters in the following tf.data API (prefetch size, interleave cycle_length, reader buffer_size)

https://www.tensorflow.org/guide/profiler (leggi best practices)

But what tells the loop to exit? And where do we call the code being monitored? We do that in a separate thread.

tracemalloc is really awesome, but unfortunately it only accounts for memory allocated by python, so if you have some c/c++ extension that does it own allocations, tracemalloc won't report it

If you only want to look at the memory usage of an object.
from pympler import asizeof
asizeof.asizeof(my_object)




ACTIVE PRIVATE WORKING SET
*This is a subset of the private working set that represents memory pages
that have been recently accessed by the process.
Windows prioritizes keeping this memory in RAM because it's actively being used.
This metric helps identify which processes are truly "active" in terms of
memory usage.
*Quando fai malloc, questa non cresce, ma cresce commited-- solo quando tocchi,
cresce.
*Nota che è working set, dunque è in ram
*Private working set is the paged-in, or "resident", subset of Private Bytes.

WORKING SET
*Working Set = Private Working Set + Shared Working Set
*These pages are not necessarily committed by the process;
(ecco perchè working set puo essere maggiore di commit)
*the memory is accessible by the processor with no page fault exception.
Simply put, the memory is in RAM (physical memory).
*Memory in the Working Set is "physical" in the sense that it can be
addressed without a page fault; however, the standby page list is also
still physically in memory but not reported in the Working Set,
and this is why you might see the "Mem Usage" suddenly drop when you
minimize an application.
*A working set is a subset of virtual pages resident in physical memory.
*In essence, a working set is used to decide how much physical memory can be
used to avoid a lot of paging. When a page fault occurs, the limits of the
working set and the amount of free memory on the system are examined.
If necessary, the memory manager allows a process to grow to its working set
maximum. If memory is tight, Windows will replace pages in a working set
when a page fault occurs.

COMMIT (PRIVATE BYTES)x2
*Commit Size only counts private allocations.
*Commit Size is the correct column to look at when trying to ascertain memory
consumption in processes. The sad thing is that it’s not the default column
shown, and that’s why many people use the misleading active private working
set column.(web)
*Private WS should always be lower than or equal to Private Bytes (web)
*Private Bytes refer to the amount of memory that the process executable has
asked for - not necessarily the amount it is actually using.
They are "private" because they (usually) exclude memory-mapped files
(i.e. shared DLLs). But - here's the catch - they don't necessarily exclude
memory allocated by those files (hared libraries can allocate memory inside
your application module). There is no way to tell whether a change
in private bytes was due to the executable itself, or due to a linked library.(web)
*Private Bytes are a reasonable approximation of the amount of memory
your executable is using and can be used to help narrow down a list
of potential candidates for a memory leak; if you see the number growing and
growing constantly and endlessly, you would want to check that process
for a leak. This cannot, however, prove that there is or is not a leak.

keras tuner (per ottimizzare)

Second, the optimizer and gradients. Depends on the optimizer too: if you're using momentum, you need to store that for
each weight, so it'll be about the same memory usage as the weights.

As shown by your model.summary(), the output size of this layer is (None, 1751, 480, 1024). For a single image, this is a total of 1751*480*1024 pixels. As your image is likely in float32, each pixel takes 4 bytes to store. So the output of this layer requires 1751*480*1024*4 bytes, which is around 3.2 GB per image just for this layer.
If you were to change the number of filters to, say, 64, you would only need around 200 MB per image.

Most critical though for images and high resolution data are the intermediate activations during training.
The frameworks must save the activations after each later to reuse when doing the backwards pass and computing
gradients. If you have a really deep network, or really high resolution images, or a whole lot of
channels/filters per layer, then the activations are your dominant memory usage

For inference or when finetuning models, freezing certain layers can help reduce memory requirements. Pruning, on
the other hand, removes parts of the model that contribute less to the overall output, reducing the number of
parameters and saving memory.
# Freezing layers
for param in model.layer1.parameters():
    param.requires_grad = False  # Freeze layer1 of ResNet
# Pruning a layer (example using torch.nn.utils.prune)
import torch.nn.utils.prune as prune
prune.l1_unstructured(model.layer2[0], name="weight", amount=0.3)  # Prune 30% of weights in layer2

multicore training?


Leverage garbage collection by explicitly deleting large tensors and running gc.collect() to free memory.

convertire in graph

https://youtu.be/_expOfB4CYg?t=2953

model pruning:
import tensorflow_model_optimization as tfmot
pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(...)
model_pruned = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule)

Note: It is not recommended to set this to "float16" for training, as this will likely cause numeric stability
issues. Instead, mixed precision, which leverages a mix of float16 and float32. It can be configured
by calling keras.mixed_precision.set_dtype_policy('mixed_float16'). (documentazione ufficiale)

Beware though if you try this API on CPU, as mixed precision is expected to run significantly slower on
such devices.
(a) In old GPU architectures and on most CPUs, FP16 numbers are treated as FP32, which requires casting to
FP32 before computations and recast back to FP16 after. This makes more operations than for FP32 numbers,
which explains why mixed precision is not preferable in such cases. This also means that if your GPU is
really old, you might also experience slower training when using mixed precision.

https://docs.openvino.ai/2025/index.html

policy_name = "mixed_float16"  # if you train on a GPU
policy_name = "mixed_bfloat16"  # if you train on a TPU
# With recent Tensorflow versions (>= 2.4)
policy = tf.keras.mixed_precision.Policy("mixed_float16")
tf.keras.mixed_precision.set_policy(policy)
# Before Tensorflow 2.4
policy = tf.keras.mixed_precision.experimental.Policy("mixed_float16")
tf.keras.mixed_precision.experimental.set_policy(policy)
optimizer = Adam(**your_parameters)
# For Tensorflow <2.4
scaled_optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, "dynamic")
# For Tensorflow >=2.4
scaled_optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer, "dynamic")

*nel caso non ti dovessi ricordare--   #tf.keras.backend.set_floatx('float16') riduceva la memoria di molto
ma visto che dovrà emulare
* su cpu colab mixedBfloat porta ad una riduzione di memoria
* su cpu colab mixedfloat è molto lento e non porta a riduzione
* su cpu colab float16 sembra ancora di piu ridurre memoria, ma è molto lento
* su cpu in realtà mi sembra che sono tutti lenti uguale -- ma mixedbfloat è piu veloce
(ma lento cmq)
* su gpu non ce nessun vantaggio di memoria
* su tpu di base è su 17/21 ma lento
* su tpu mixedloat float 17
*su tpu mixedbfloat 17

tf.config.optimizer.set_jit(True)

tf.keras.backend.clear_session()


ricorda che con la gpu print(tf.config.experimental.get_memory_info('GPU:0')) il peak è sempre
costante.

nella seconda versione vuole che W1 sia definito con indici ordinati--ho paura che nella prima versione
li va a riordinare da solo
hidden = tf.sparse.sparse_dense_matmul(X, self.W1)
#hidden = tf.matmul(X, tf.sparse.to_dense(self.W1))


Convert W_indices and W_shapes to TensorFlow constants during initialization to avoid repeated conversions during forward passes.


This uses sparse to dense op, which is mostly deprecated in favor of scatter_nd op. That op has a gradient.
We should change the sparse to dense Python wrapper to call scatter_nd.


Here is the solution.
open YOURPATH/tensorflow/python/ops/sparse_grad.py
Remove line 33 ops.NotDifferentiable("SparsetoDense")
At the end, append
@ops.RegisterGradient("SparseToDense")
def _SparseToDenseGrad(op, grad):
sparse_indices, output_shape, _, _ = op.inputs
sparse_values_grad = array_ops.gather_nd(grad, sparse_indices)
default_value_grad = math_ops.reduce_sum(grad) - math_ops.reduce_sum(
sparse_values_grad)
return [
array_ops.zeros_like(sparse_indices),
array_ops.zeros_like(output_shape), sparse_values_grad, default_value_grad
]
This implementation is from TF2.0 version.


E se provassi ad usare assign() su sparse tensor per modificare il valore invece di ricrearlo di nuovo?

da qualche parte uso vettoru numpy, da qualche altra parte vettrori std di python -- deve essere uniforme

https://github.com/tensorflow/tensorflow/issues/46089
https://github.com/tensorflow/tensorflow/issues/46706

sparse_softmax
sparse_dense_cwise_mul in un eventuale tua adagrad?
sparse_concat in regrow_layer?
serialize_many_sparse?


If you would like to define the tensor outside the graph, e.g. define the sparse tensor for later data feed, use SparseTensorValue. In contrast, if the sparse tensor is defined in graph, use SparseTensor

sparse_tensor_dense_mat_mul vanno bene indici int32


x = tf.keras.Input(shape=(4,), sparse=True)
y = tf.keras.layers.Dense(4)(x)
model = tf.keras.Model(x, y)
sparse_data = tf.sparse.SparseTensor(
    indices = [(0,0),(0,1),(0,2),
               (4,3),(5,0),(5,1)],
    values = [1,1,1,1,1,1],
    dense_shape = (6,4)
)
model(sparse_data)
model.predict(sparse_data)

fare anche l'output sparso?


tf.raw_ops.SparseTensorDenseMatMul


controlla se tutte le funzioni su cui si poteva fare checkoiint sono state fatte (anhe fully connected in fondo)/ batch norm

128
keras
(28508.8125, 36142.96875, 7805.6484375, 36142.96875)  normale
(8553.5, 19235.9609375, 9605.62109375, 19235.9609375) check

sparse2
(9682.0, 19059.828125, 9271.3125, 19059.828125) sp = 1
(9685.6,  19075.703125, 8585.84375, 19075.703125) sp=0.99
(10144.7, 19554.6875,  10225.21875, 19554.6875) sp=0.5
(10104.6376953125, 19772.171875, 10502.76171875, 19772.171875) sp=0.2
(9904.4375, 20044.875, 10551.13671875, 20044.875) sp= 0

original
(29339.75, 36127, 9552, 36127)





sparse2 con check point 128

sp = 1
(9682.0, 19058.640625, 9321.71875, 19058.640625)
(9682.0, 19061.83203125, 10066.9296875, 19091.125)
(9682.0, 19061.83203125, 10156.29296875, 19093.9140625)
(9682.0, 19061.83203125, 10267.421875, 19093.9375)
(9682.0, 19062.33984375, 10345.84375, 19093.9453125)
(9682.0, 19062.33984375, 10345.84375, 19094.4140625)

sp=0.1
(9985.10009765625, 19846.09765625, 10671.87890625, 19846.09765625)
(10206.71337890625, 19850.5703125, 11071.5234375, 19868.33203125)
(10206.71337890625, 19851.7109375, 11525.6953125, 19882.69140625)
(10206.71337890625, 19851.6484375, 11525.6953125, 19883.7890625)

sp = 0
(9904.4375, 20044.12109375, 10158.86328125,20044.12109375)
(10333.75, 20047.79296875, 10575.91796875, 20065.70703125)
(10333.75, 20048.3046875, 10575.91796875,  20066.94140625)
(10333.75, 20048.3046875, 11411.55078125,  20080.41796875)


sparse2 senza check 128
(29569.75, 36975.89453125, 8932.04296875, 36975.89453125) sp = 0
(29511.75, 35990.67578125, 11982.3515625, 35990.67578125) sp = 1 però molto piu veloce


sparse2 con checkpointing
sp = 0
(2758.6875, 7346.7421875, 5298.046875, 7346.7421875)
(3036.5, 7350.4296875, 5663.6953125, 7367.98046875)
(3136.9375, 7350.7265625, 5762.0703125, 7368.8828125)
(3159.1875, 7350.7265625, 5828.42578125, 7369.26953125)
(3159.1875, 7350.921875, 5844.4765625, 7369.30859375)
(3159.1875, 7350.921875, 5844.71484375, 7369.484375)
(3266.6875, 7350.921875, 5926.734375, 7369.484375)
(3285.625, 7350.921875, 5977.8125, 7369.484375)
(3285.625, 7350.921875, 5993.828125, 7369.50390625)
(3306.125, 7350.95703125, 5993.84375, 7369.50390625)
(3306.125, 7351.2109375, 5993.9609375, 7369.73828125)
(3306.125, 7351.2109375, 6174.20703125, 7369.765625)
(3306.125, 7351.2109375, 6190.21484375, 7369.78125)
(3306.125, 7351.2109375, 6190.22265625, 7369.78125)
(3306.125, 7351.2109375, 6190.22265625, 7369.7890625)
(3306.125, 7351.2109375, 6190.22265625, 7369.7890625)
(3306.125, 7351.2109375, 6190.22265625, 7369.7890625)
(3306.125, 7351.2109375, 6190.22265625, 7369.79296875)

sp = 1
(2415.5, 6359.5, 4307.453125, 6359.5)
(2415.5, 6361.8828125, 4325.28515625, 6380.26953125)
(2495.125, 6361.8828125, 4408.05859375, 6380.44921875)
(2495.125, 6362.19921875, 4424.1796875, 6380.5703125)
(2495.125, 6362.35546875, 4424.49609375, 6380.7890625)
(2495.125, 6362.35546875, 4424.6328125, 6380.90625)
(2495.125, 6362.34765625, 4424.65234375, 6380.90625)
(2495.125, 6362.4453125, 4424.71484375, 6380.9140625)
(2495.125, 6362.4453125, 4424.828125, 6380.97265625)
(2495.125, 6362.4453125, 4424.83984375, 6381.02734375)
(2495.125, 6362.4453125, 4424.8515625, 6381.02734375)

sp = 0.8
(2525.625, 6546.91015625, 4578.87109375, 6546.91015625)
(2814.53857421875, 6552.8203125, 4990.95703125, 6570.91796875)
(2814.53857421875, 6553.76171875, 5006.9921875, 6571.56640625)
(2814.53857421875, 6553.9609375, 5014.44140625, 6572.34765625)
(2814.53857421875, 6554.05859375, 5017.12890625, 6572.49609375)
(2814.53857421875, 6553.953125, 5017.24609375, 6572.5)
(2815.5380859375, 6553.953125, 5017.24609375, 6572.5)
(2815.5380859375, 6553.953125, 5017.25390625, 6572.5)
(2815.5380859375, 6554.20703125, 5017.390625, 6572.77734375)
(2815.5380859375, 6554.20703125, 5017.66015625, 6572.77734375)


sparse2 senza check N = 1
(701.991943359375, 3291.5546875, 2564.76171875, 3291.5546875) sp = 0.9
(782.56640625, 4164.83203125, 3435.76171875, 4164.83203125) sp = 0


batch = 32
(2273.60009765625, 6575.453125, 4434.5, 6594.0390625) check, sp = 0.8 (17 steps)
(2754.4375, 7371.7109375, 5432.296875, 7390.2734375): check, sp = 0 (17 steps)

(7963.1875, 10810.078125, 8531.21484375, 10842.0859375) no check  sp = 0.8 (10 step)
(8235.8125, 11606.19921875, 9212.96875, 11638.35546875) no check, sp = 0 (24 steps)







C:\Users\Xino\PycharmProjects\HDA\.venv\Scripts\python.exe C:\Users\Xino\PycharmProjects\HDA\models.py
2025-06-03 08:25:39.071873: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-06-03 08:25:40.888147: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-06-03 08:25:44.622631: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Loaded subset: (1195, 224, 224, 3), (1195, 8)
Training from scratch

Epoch 1
Step 2, Loss: 2.079441547393799
Step 3, Loss: 2.189054012298584
Step 4, Loss: 2.1762876510620117
Step 5, Loss: 2.669844627380371
Step 6, Loss: 1.8165137767791748
Step 7, Loss: 2.3282341957092285
Step 8, Loss: 1.9997813701629639
Step 9, Loss: 2.103971481323242
Step 10, Loss: 1.9409513473510742
Step 11, Loss: 1.9501467943191528
Step 12, Loss: 1.9471850395202637
Step 13, Loss: 2.007359504699707
Step 14, Loss: 1.8740845918655396
Step 15, Loss: 2.3448736667633057
Step 16, Loss: 2.121858835220337
Step 17, Loss: 1.9928216934204102
Step 18, Loss: 1.967025876045227
Step 19, Loss: 2.635105609893799
Step 20, Loss: 2.221766471862793
Step 21, Loss: 2.073448657989502
Step 22, Loss: 2.262620449066162
Step 23, Loss: 1.970413088798523
Step 24, Loss: 1.9626911878585815
Step 25, Loss: 2.3942952156066895
Step 26, Loss: 2.151484489440918
Step 27, Loss: 2.038832664489746
Step 28, Loss: 1.9878263473510742
Step 29, Loss: 1.8645930290222168
Step 30, Loss: 1.9358429908752441
Step 31, Loss: 2.4518327713012695



